# âš¡ LUMINA - Intelligent File Reader

<div align="center">
  <h3>ğŸ¤– Your AI-Powered Document Assistant</h3>
  <p>Upload PDFs and chat with your documents using advanced RAG (Retrieval-Augmented Generation) technology</p>
  
  ![Version](https://img.shields.io/badge/Version-1.0.0-blue?style=for-the-badge)
  ![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)
  ![Python](https://img.shields.io/badge/Python-3.8+-yellow?style=for-the-badge&logo=python)
  ![React Native](https://img.shields.io/badge/React_Native-0.81-61DAFB?style=for-the-badge&logo=react)
  [![codecov](https://codecov.io/gh/Pranit-satnurkar/LUMINA-INTELLIGENT-FILE-READER-/branch/main/graph/badge.svg)](https://codecov.io/gh/Pranit-satnurkar/LUMINA-INTELLIGENT-FILE-READER-)
</div>

---

## ğŸ“– Overview

**LUMINA** is an intelligent document reader that leverages cutting-edge AI technology to help you interact with your PDF documents through natural language conversations. Built with a robust RAG architecture, LUMINA combines the power of LangChain, Groq LLM, and FAISS vector search to provide accurate, context-aware responses to your questions.

### ğŸ¯ Key Highlights

- **Advanced RAG Pipeline**: Hybrid search combining FAISS vector similarity and BM25 ranking
- **Multi-Platform**: Web interface (Streamlit) + Mobile app (React Native/Expo)
- **Intelligent Processing**: Recursive character splitting for context preservation
- **Security-First**: Pydantic guardrails, conversation sandboxing, and prompt isolation
- **Evaluation Metrics**: RAGAS integration for faithfulness, relevancy, and context recall
- **Expert Tools**: Specialized document analysis capabilities

---

## âœ¨ Features

### ğŸš€ Core Functionality
- ğŸ“„ **PDF Upload & Processing** - Support for multiple PDF documents with intelligent chunking
- ğŸ’¬ **AI Chat Interface** - Natural language conversations about your documents
- ğŸ” **Hybrid Search** - Combined vector similarity (FAISS) and keyword search (BM25)
- ğŸ¯ **Context-Aware Responses** - Maintains conversation history for coherent interactions
- âš¡ **Fast Inference** - Powered by Groq's lightning-fast LLM API

### ğŸ¨ User Experience
- ğŸŒ™ **Dark/Light Mode** - Beautiful themes for comfortable reading
- ğŸ“± **Mobile App** - Native Android experience with React Native
- ğŸ–¥ï¸ **Web Interface** - Streamlit-based dashboard for desktop users
- ğŸ’¾ **Session Management** - Persistent chat history and document context

### ğŸ”’ Security & Quality
- âœ… **HTTPS Encryption** - Secure API communication
- âœ… **Conversation Sandbox** - Isolated execution environment
- âœ… **Pydantic Guardrails** - Input validation and type safety
- âœ… **RAGAS Evaluation** - Quality metrics for response accuracy
- âœ… **No Data Persistence** - Documents processed in-memory only

---

## ğŸ“¸ Screenshots

### Web Interface

<div align="center">

**Home & Upload Interface**

![Web Home](screenshots/web-home.png)

**AI Chat with Document Analysis**

![Web Chat](screenshots/web-chat.png)

</div>

### Mobile App

<div align="center">

**Document Upload**

<img src="screenshots/mobile-home.png" width="300" alt="Mobile Home"/>

**Chat Interface**

<img src="screenshots/mobile-chat.png" width="300" alt="Mobile Chat"/>

**Settings**

<img src="screenshots/mobile-settings.png" width="300" alt="Mobile Settings"/>

</div>

---

## ğŸ—ï¸ Architecture


```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LUMINA Architecture                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Mobile App â”‚         â”‚ Web Interfaceâ”‚                 â”‚
â”‚  â”‚ (React Native)â”‚         â”‚  (Streamlit) â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                         â”‚                          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                   â”‚                                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚         â”‚   FastAPI Backend  â”‚                               â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                               â”‚
â”‚         â”‚  â”‚  Security    â”‚ â”‚                               â”‚
â”‚         â”‚  â”‚  Layer       â”‚ â”‚                               â”‚
â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                               â”‚
â”‚         â”‚         â”‚          â”‚                               â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚                               â”‚
â”‚         â”‚  â”‚ LangChain    â”‚ â”‚                               â”‚
â”‚         â”‚  â”‚ Agent        â”‚ â”‚                               â”‚
â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                               â”‚
â”‚         â”‚         â”‚          â”‚                               â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚                               â”‚
â”‚         â”‚  â”‚ PDF Processorâ”‚ â”‚                               â”‚
â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                   â”‚                                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚         â”‚  Hybrid Search     â”‚                               â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”‚                               â”‚
â”‚         â”‚  â”‚FAISS â”‚ â”‚BM25 â”‚ â”‚                               â”‚
â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â”‚                               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                   â”‚                                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚         â”‚   Groq LLM API    â”‚                               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Tech Stack

### Backend
| Technology | Purpose |
|-----------|---------|
| **FastAPI** | Modern Python web framework for API endpoints |
| **LangChain** | LLM orchestration and RAG pipeline |
| **LangGraph** | Agent workflow management |
| **Groq** | Ultra-fast LLM inference (llama-3.3-70b-versatile) |
| **FAISS** | Vector similarity search (Facebook AI) |
| **Sentence Transformers** | Document embeddings (all-MiniLM-L6-v2) |
| **BM25** | Keyword-based ranking algorithm |
| **PDFPlumber** | PDF text extraction |
| **Pydantic** | Data validation and settings management |
| **RAGAS** | RAG evaluation metrics |

### Frontend
| Technology | Purpose |
|-----------|---------|
| **React Native** | Cross-platform mobile framework |
| **Expo** | Development and build platform |
| **Streamlit** | Web dashboard interface |
| **Axios** | HTTP client for API calls |

### DevOps & Tools
| Technology | Purpose |
|-----------|---------|
| **Uvicorn** | ASGI server for FastAPI |
| **Gunicorn** | Production WSGI server |
| **Python-dotenv** | Environment variable management |
| **Git** | Version control |

---

## ğŸ“¦ Project Structure

```
RAG-Powered-Chatbot/
â”œâ”€â”€ backend/                    # FastAPI backend service
â”‚   â”œâ”€â”€ main.py                # API endpoints and server setup
â”‚   â”œâ”€â”€ bot.py                 # LangChain agent and RAG logic
â”‚   â”œâ”€â”€ pdf_processor.py       # PDF parsing and chunking
â”‚   â”œâ”€â”€ expert_tools.py        # Specialized document tools
â”‚   â”œâ”€â”€ security_layer.py      # Security and validation
â”‚   â””â”€â”€ faiss_index/           # Vector database storage
â”‚
â”œâ”€â”€ mobile-app/                # React Native mobile application
â”‚   â”œâ”€â”€ App.js                 # Main mobile app component
â”‚   â”œâ”€â”€ app.json               # Expo configuration
â”‚   â”œâ”€â”€ eas.json               # EAS Build configuration
â”‚   â””â”€â”€ assets/                # App icons and images
â”‚
â”œâ”€â”€ api/                       # Additional API utilities
â”œâ”€â”€ docs/                      # Documentation files
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚
â”œâ”€â”€ app.py                     # Streamlit web interface
â”œâ”€â”€ ingest.py                  # Document ingestion pipeline
â”œâ”€â”€ evaluate.py                # RAGAS evaluation script
â”œâ”€â”€ hybrid_search.py           # Hybrid search implementation
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # Environment variables (not in repo)
â”œâ”€â”€ .gitignore                # Git ignore rules
â””â”€â”€ README.md                  # This file
```

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- Node.js 16+ and npm (for mobile app)
- Git
- Groq API key ([Get it here](https://console.groq.com))

### Backend Setup

1. **Clone the repository**
```bash
git clone https://github.com/Pranit-satnurkar/LUMINA-INTELLIGENT-FILE-READER-.git
cd LUMINA-INTELLIGENT-FILE-READER-
```

2. **Create virtual environment**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
# Create .env file
echo GROQ_API_KEY=your_groq_api_key_here > .env
```

5. **Run the backend server**
```bash
# Development mode
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

# Or use the Streamlit interface
streamlit run app.py
```

### Mobile App Setup

1. **Navigate to mobile app directory**
```bash
cd mobile-app
```

2. **Install dependencies**
```bash
npm install
```

3. **Update API endpoint**
```javascript
// In App.js, update the API_URL to your backend URL
const API_URL = 'http://your-backend-url:8000';
```

4. **Start Expo development server**
```bash
npx expo start
```

5. **Run on device**
- Install Expo Go app on your Android/iOS device
- Scan the QR code from the terminal
- Or press `a` for Android emulator, `i` for iOS simulator

---

## ğŸ“± Usage

### Web Interface (Streamlit)

1. Start the Streamlit app:
```bash
streamlit run app.py
```

2. Open your browser at `http://localhost:8501`

3. Upload PDF documents using the sidebar

4. Ask questions in the chat interface

### Mobile App

1. Launch the app on your device

2. Tap the "Upload PDF" button

3. Select a PDF from your device

4. Start chatting with your document!

### API Endpoints

```bash
# Health check
GET http://localhost:8000/health

# Upload PDF
POST http://localhost:8000/api/upload
Content-Type: multipart/form-data
Body: file=<pdf_file>

# Chat with document
POST http://localhost:8000/api/chat
Content-Type: application/json
Body: {
  "message": "What is this document about?",
  "session_id": "unique-session-id"
}
```

---

## ğŸ§ª Evaluation & Testing

LUMINA uses **RAGAS** (Retrieval-Augmented Generation Assessment) for quality evaluation:

```bash
# Run evaluation
python evaluate.py
```

### Metrics Tracked
- **Faithfulness**: How accurate are the responses based on retrieved context?
- **Answer Relevancy**: How relevant are the answers to the questions?
- **Context Recall**: How well does the system retrieve relevant context?
- **Context Precision**: How precise is the retrieved context?

**Target**: Faithfulness score > 0.9

---

## ğŸ” Security Features

1. **Conversation Sandbox**: Bot is restricted from accessing system prompts or unauthorized files
2. **Pydantic Guardrails**: Type validation and input sanitization
3. **HTTPS Encryption**: All API communications are encrypted
4. **No Data Persistence**: Documents are processed in-memory only
5. **Environment Variables**: Sensitive keys stored securely
6. **CORS Configuration**: Controlled cross-origin access

---

## ğŸ¯ Roadmap

- [x] Core RAG pipeline with FAISS + BM25
- [x] Mobile app with React Native
- [x] Web interface with Streamlit
- [x] RAGAS evaluation integration
- [x] Security layer implementation
- [ ] Multi-document conversation support
- [ ] OCR for scanned PDFs
- [ ] Support for DOCX, TXT, and other formats
- [ ] Cloud deployment (Railway/Render)
- [ ] User authentication
- [ ] Document annotation features

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LangChain** - For the amazing RAG framework
- **Groq** - For lightning-fast LLM inference
- **Facebook AI** - For FAISS vector search
- **Expo** - For simplifying React Native development
- **Streamlit** - For the beautiful web interface

---

## ğŸ“§ Contact

**Pranit Satnurkar**

- GitHub: [@Pranit-satnurkar](https://github.com/Pranit-satnurkar)
- Repository: [LUMINA-INTELLIGENT-FILE-READER-](https://github.com/Pranit-satnurkar/LUMINA-INTELLIGENT-FILE-READER-)

---

<div align="center">
  <p><strong>âš¡ Built with passion using Google Antigravity & Gemini 3 Pro</strong></p>
  <p>â­ Star this repo if you find it useful!</p>
  <p>Made with â¤ï¸ for the AI community</p>
</div>
